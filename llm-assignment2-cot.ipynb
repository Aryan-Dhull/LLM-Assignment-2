{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[],"dockerImageVersionId":30761,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install transformers datasets torch","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-09-22T08:00:44.724478Z","iopub.execute_input":"2024-09-22T08:00:44.724782Z","iopub.status.idle":"2024-09-22T08:00:53.554578Z","shell.execute_reply.started":"2024-09-22T08:00:44.724752Z","shell.execute_reply":"2024-09-22T08:00:53.553474Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import time\nfrom transformers import AutoModelForCausalLM, AutoTokenizer\nfrom datasets import load_dataset\nimport torch\nimport re","metadata":{"execution":{"iopub.status.busy":"2024-09-22T08:00:53.556574Z","iopub.execute_input":"2024-09-22T08:00:53.556874Z","iopub.status.idle":"2024-09-22T08:01:17.444110Z","shell.execute_reply.started":"2024-09-22T08:00:53.556842Z","shell.execute_reply":"2024-09-22T08:01:17.442970Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dataset = load_dataset(\"cais/mmlu\", \"college_mathematics\")\ntest_data = dataset['test']","metadata":{"execution":{"iopub.status.busy":"2024-09-22T08:01:17.445035Z","iopub.execute_input":"2024-09-22T08:01:17.445431Z","iopub.status.idle":"2024-09-22T08:01:22.670894Z","shell.execute_reply.started":"2024-09-22T08:01:17.445402Z","shell.execute_reply":"2024-09-22T08:01:22.670086Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def load_model_and_tokenizer(model_name):\n    tokenizer = AutoTokenizer.from_pretrained(model_name, use_auth_token=\"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\")\n    model = AutoModelForCausalLM.from_pretrained(model_name, use_auth_token=\"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\")\n    return model, tokenizer","metadata":{"execution":{"iopub.status.busy":"2024-09-22T08:01:22.672534Z","iopub.execute_input":"2024-09-22T08:01:22.672905Z","iopub.status.idle":"2024-09-22T08:01:22.676662Z","shell.execute_reply.started":"2024-09-22T08:01:22.672879Z","shell.execute_reply":"2024-09-22T08:01:22.675996Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def evaluate_model(model, tokenizer, test_data, prompt_template):\n    total_time = 0\n    correct = 0\n    total = len(test_data)\n\n    for i in range(total):\n        question = test_data[i]['question']\n        options = [test_data[i]['choices'][j] for j in range(4)]\n        correct_answer = test_data[i]['choices'][test_data[i]['answer'] - 1]\n\n        prompt = prompt_template.format(question=question, options=\"\\n\".join(options))\n\n        inputs = tokenizer(prompt, return_tensors=\"pt\")\n\n        start_time = time.time()\n        outputs = model.generate(**inputs, max_new_tokens=100)\n        inference_time = time.time() - start_time\n        total_time += inference_time\n\n        generated_text = tokenizer.decode(outputs[0], skip_special_tokens=True)\n        \n        match = re.search(r\"(The correct answer is|Answer is|Answer\\s*:|answer is)\\s*(.+)\", generated_text, re.IGNORECASE)\n        if match:\n            generated_answer = match.group(2).strip()\n        else:\n            generated_answer = None\n        \n        if generated_answer and (correct_answer in generated_answer or generated_answer in correct_answer):\n            correct += 1\n    \n    accuracy = correct / total\n    avg_inference_time = total_time / total\n\n    return accuracy, avg_inference_time","metadata":{"execution":{"iopub.status.busy":"2024-09-22T08:01:22.677907Z","iopub.execute_input":"2024-09-22T08:01:22.678182Z","iopub.status.idle":"2024-09-22T08:01:22.696021Z","shell.execute_reply.started":"2024-09-22T08:01:22.678156Z","shell.execute_reply":"2024-09-22T08:01:22.695366Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def run_evaluation(models, test_data):\n    results = {}\n    prompt_template = \"Choose answer of given question from below options.\\nQuestion: {question}\\n{options}\\nThink step by step.\"\n    for model_name, model_path in models.items():\n        print(f\"Loading model: {model_name}\")\n        model, tokenizer = load_model_and_tokenizer(model_path)\n\n        print(f\"Evaluating {model_name} with Chain of thought prompt...\")\n        accuracy, avg_inference_time = evaluate_model(model, tokenizer, test_data, prompt_template)\n        results[(model_name, 'chain_of_thought')] = (accuracy, avg_inference_time)\n\n        print(f\"Accuracy: {accuracy}, Avg Inference Time: {avg_inference_time}\")\n        print()\n\n    return results","metadata":{"execution":{"iopub.status.busy":"2024-09-22T08:01:22.696852Z","iopub.execute_input":"2024-09-22T08:01:22.697088Z","iopub.status.idle":"2024-09-22T08:01:22.706399Z","shell.execute_reply.started":"2024-09-22T08:01:22.697064Z","shell.execute_reply":"2024-09-22T08:01:22.705699Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"models = {\n    \"Gemma-2B\": \"google/gemma-2b-it\",\n    \"Phi-3.5-mini\": \"microsoft/Phi-3.5-mini-instruct\",\n    \"Meta-Llama-3.1-8B\": \"meta-llama/Meta-Llama-3.1-8B-Instruct\"\n}","metadata":{"execution":{"iopub.status.busy":"2024-09-22T08:01:22.707239Z","iopub.execute_input":"2024-09-22T08:01:22.707495Z","iopub.status.idle":"2024-09-22T08:01:22.720220Z","shell.execute_reply.started":"2024-09-22T08:01:22.707470Z","shell.execute_reply":"2024-09-22T08:01:22.719549Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"results = run_evaluation(models, test_data)","metadata":{"execution":{"iopub.status.busy":"2024-09-22T08:01:22.721253Z","iopub.execute_input":"2024-09-22T08:01:22.721521Z","iopub.status.idle":"2024-09-22T09:40:21.097002Z","shell.execute_reply.started":"2024-09-22T08:01:22.721495Z","shell.execute_reply":"2024-09-22T09:40:21.096039Z"},"trusted":true},"execution_count":null,"outputs":[]}]}